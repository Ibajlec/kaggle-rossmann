{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pandas_summary import DataFrameSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('train_normalized_data.fth')\n",
    "df_test = pd.read_feather('test_normalized_data.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.Date < datetime.datetime(2015, 7, 1)]  \n",
    "df_val = df[df.Date >= datetime.datetime(2015, 7, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric(sales, sales_):\n",
    "    return (((sales - sales_)/sales)**2).sum()/len(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$\\textrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(\\frac{\\hat{y}_i - y_i}{y_i}\\right)^2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open',\n",
       "       'Promo', 'StateHoliday', 'SchoolHoliday', 'Year', 'Month', 'Week',\n",
       "       'Day', 'StoreType', 'Assortment', 'CompetitionDistance',\n",
       "       'CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear', 'Promo2',\n",
       "       'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval',\n",
       "       'CompetitionOpenSince', 'Promo2Since', 'State', 'file', 'week', 'trend',\n",
       "       'Date_y', 'Month_y', 'Day_y', 'file_DE', 'week_DE', 'trend_DE',\n",
       "       'Date_DE', 'State_DE', 'Month_DE', 'Day_DE', 'file_y',\n",
       "       'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n",
       "       'Dew_PointC', 'MeanDew_PointC', 'Min_DewpointC', 'Max_Humidity',\n",
       "       'Mean_Humidity', 'Min_Humidity', 'Max_Sea_Level_PressurehPa',\n",
       "       'Mean_Sea_Level_PressurehPa', 'Min_Sea_Level_PressurehPa',\n",
       "       'Max_VisibilityKm', 'Mean_VisibilityKm', 'Min_VisibilitykM',\n",
       "       'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h', 'Max_Gust_SpeedKm_h',\n",
       "       'Precipitationmm', 'CloudCover', 'Events', 'WindDirDegrees',\n",
       "       'StateName', 'Year_y', 'Week_y', 'CompetitionDaysOpen',\n",
       "       'CompetitionMonthsOpen', 'Promo2Days', 'Promo2Weeks',\n",
       "       'StateHoliday_bool', 'AfterSchoolHoliday', 'BeforeSchoolHoliday',\n",
       "       'AfterStateHoliday_bool', 'BeforeStateHoliday_bool', 'AfterPromo',\n",
       "       'BeforePromo', 'SchoolHoliday_bw', 'StateHoliday_bool_bw', 'Promo_bw',\n",
       "       'SchoolHoliday_fw', 'StateHoliday_bool_fw', 'Promo_fw', 'Sales_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30188     20\n",
       "30189     20\n",
       "30190      0\n",
       "30191     20\n",
       "30192     20\n",
       "          ..\n",
       "844333    10\n",
       "844334    10\n",
       "844335    10\n",
       "844336     1\n",
       "844337    10\n",
       "Name: Events, Length: 814150, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales = df_train['Sales'].max()\n",
    "df.loc[:, 'Sales_norm'] = df['Sales'].values/max_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usuario/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/usuario/anaconda3/envs/tensorflow2/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df_train.loc[:, 'Sales_norm'] = df_train['Sales'].values/max_sales\n",
    "df_val.loc[:, 'Sales_norm'] = df_val['Sales'].values/max_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "0.4059077987085825\n",
      "Val:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30213969475255925"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train:')\n",
    "print(get_metric(df_train['Sales_norm'], \n",
    "                 df_train['Sales_norm'].mean()))\n",
    "print('Val:')\n",
    "get_metric(df_val['Sales_norm'], \n",
    "           df_train['Sales_norm'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_by_column(column, sales_str):\n",
    "    group_means_dict = {}\n",
    "    group_mean_list = []\n",
    "    for col_value, group_df in df_train.groupby(column):\n",
    "        group_mean =  group_df[group_df[sales_str] > 0][sales_str].mean()\n",
    "        group_means_dict[col_value] = group_mean\n",
    "        group_mean_list.append(group_mean)\n",
    "    print('Train:', get_metric(df_train[sales_str], \n",
    "                               df_train[column].apply(group_means_dict.get)))\n",
    "    print('Val:', get_metric(df_val[sales_str], \n",
    "                             df_val[column].apply(group_means_dict.get)))\n",
    "    return group_means_dict, group_mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.15688835922756375\n",
      "Val: 0.09435624012794681\n"
     ]
    }
   ],
   "source": [
    "# Media por store\n",
    "_ = get_mean_by_column('Store', 'Sales_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.36106577837306253\n",
      "Val: 0.2561769086693393\n"
     ]
    }
   ],
   "source": [
    "# Media por dia de la semana\n",
    "_ = get_mean_by_column('DayOfWeek', 'Sales_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.3693486112676764\n",
      "Val: 0.2674408728623329\n"
     ]
    }
   ],
   "source": [
    "# Media por numera de semana (1-52)\n",
    "_ = get_mean_by_column('Week', 'Sales_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.4002726878411708\n",
      "Val: 0.2964421798587632\n"
     ]
    }
   ],
   "source": [
    "_ = get_mean_by_column('Month', 'Sales_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.4070020265579082\n",
      "Val: 0.30186165673507453\n"
     ]
    }
   ],
   "source": [
    "_ = get_mean_by_column('StateHoliday', 'Sales_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.4034957752536508\n",
      "Val: 0.3050227258443403\n"
     ]
    }
   ],
   "source": [
    "_ = get_mean_by_column('SchoolHoliday', 'Sales_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Embedding, Input, Flatten, Concatenate, Dense, BatchNormalization, Activation, LeakyReLU, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return K.mean(K.square((y_true - y_pred)/y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_LR(X_columns):\n",
    "    inputs = []\n",
    "    for i, col in enumerate(X_columns):\n",
    "        inp = Input(shape=(X_train[i].shape[1],), name=f\"{col}_input\")\n",
    "        inputs.append(inp)\n",
    "    if len(X_columns)>1:\n",
    "        concat_out = Concatenate()(inputs)\n",
    "        dense_out = Dense(1, name='Dense')(concat_out)\n",
    "    else:\n",
    "        dense_out = Dense(1, name='Dense')(inputs[0])\n",
    "    model = Model(inputs, dense_out)\n",
    "    model.compile(optimizers.Adam(lr=0.0001), loss='mse', metrics=[rmspe, 'mse'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_embedings_NN(X_columns, hidden_units = 20, activation = 'relu'):\n",
    "    embed_outs = []\n",
    "    inputs = []\n",
    "    for i, col in enumerate(X_columns):\n",
    "        inp = Input(shape=(1,), name=f\"{col}_input\")\n",
    "        inputs.append(inp)\n",
    "        embed_out = Embedding(len(np.unique(X_train[i])), embed_outs_dict[col], name=f\"{col}_embedding\", mask_zero=False)(inp)\n",
    "        out = Flatten(name=f\"{col}_flatten\")(embed_out)\n",
    "        embed_outs.append(out)\n",
    "    if len(X_columns)>1:\n",
    "        concat_out = Concatenate()(embed_outs)\n",
    "        dense_out = Dense(hidden_units, activation=activation)(concat_out)\n",
    "    else:\n",
    "        dense_out = Dense(hidden_units, activation=activation)(out)\n",
    "    out = Dense(1)(dense_out)\n",
    "    model = Model(inputs, out)\n",
    "    model.compile(optimizers.Adam(lr=0.0001), loss='mse', metrics=[rmspe, 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = True\n",
    "\n",
    "embed_outs_dict = {'Store': 50, 'DayOfWeek': 2, 'Week': 10, 'Month': 4}\n",
    "embed_outs_dict = {'Store': 50}\n",
    "X_columns = list(embed_outs_dict.keys())\n",
    "\n",
    "if final_train:\n",
    "    X_train = np.hsplit(df[X_columns].values, len(X_columns))\n",
    "    y_train = df['Sales_norm']\n",
    "else:\n",
    "    X_train = np.hsplit(df_train[X_columns].values, len(X_columns))\n",
    "    y_train = df_train['Sales_norm']\n",
    "    \n",
    "X_val = np.hsplit(df_val[X_columns].values, len(X_columns))\n",
    "X_test = np.hsplit(df_test[X_columns].values, len(X_columns))\n",
    "\n",
    "if log_reg:\n",
    "    for i in range(len(X_train)):\n",
    "        X_train[i] = to_categorical(X_train[i])\n",
    "        X_val[i] = to_categorical(X_val[i])\n",
    "        X_test[i] = to_categorical(X_test[i])\n",
    "\n",
    "y_val = df_val['Sales_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Store_input (InputLayer)     [(None, 1115)]            0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 1116      \n",
      "=================================================================\n",
      "Total params: 1,116\n",
      "Trainable params: 1,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if not log_reg:\n",
    "    model = get_embedings_NN(X_columns)\n",
    "else:\n",
    "    model = get_keras_LR(X_columns)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = model.get_weights()\n",
    "# weights[0] = np.array(np.array(stores_mean_list).reshape(-1, 1))\n",
    "# model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944/944 [==============================] - 1s 721us/step - loss: 0.0359 - rmspe: 1.1011 - mse: 0.0359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03587775677442551, 1.1010745763778687, 0.03587775677442551]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25443/25443 [==============================] - 22s 865us/step - loss: 0.0038 - rmspe: 0.2067 - mse: 0.0038 - val_loss: 0.0018 - val_rmspe: 0.0960 - val_mse: 0.0018\n",
      "Epoch 2/5\n",
      "25443/25443 [==============================] - 22s 864us/step - loss: 0.0023 - rmspe: 0.1580 - mse: 0.0023 - val_loss: 0.0018 - val_rmspe: 0.0942 - val_mse: 0.0018\n",
      "Epoch 3/5\n",
      "25443/25443 [==============================] - 22s 871us/step - loss: 0.0023 - rmspe: 0.1569 - mse: 0.0023 - val_loss: 0.0017 - val_rmspe: 0.0948 - val_mse: 0.0017\n",
      "Epoch 4/5\n",
      "25443/25443 [==============================] - 22s 866us/step - loss: 0.0023 - rmspe: 0.1583 - mse: 0.0023 - val_loss: 0.0017 - val_rmspe: 0.0943 - val_mse: 0.0017\n",
      "Epoch 5/5\n",
      "25443/25443 [==============================] - 22s 870us/step - loss: 0.0023 - rmspe: 0.1567 - mse: 0.0023 - val_loss: 0.0018 - val_rmspe: 0.0944 - val_mse: 0.0018\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "if final_train:\n",
    "    model.fit(X_train, y_train, epochs=epochs)\n",
    "else:\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944/944 [==============================] - 1s 716us/step - loss: 0.0018 - rmspe: 0.0944 - mse: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0017532232450321317, 0.09439808875322342, 0.0017532232450321317]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Store, DayOfWeek: 0.09212721139192581, 0.048540305346250534\n",
    "Store, DayOfWeek, Week: 0.0615, 0.02256705053150654\n",
    "Store, DayOfWeek, Week, Month: 0.061621, 0.02359057404100895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06149980579432537"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = model.predict(X_train)*max_sales\n",
    "get_metric(df_train['Sales'].values, train_predictions.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)*max_sales\n",
    "test_predictions[df_test['Open'] == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv = pd.read_csv('dataset/rossmann/sample_submission.csv')\n",
    "sample_csv['Sales'] = test_predictions\n",
    "sample_csv.head()\n",
    "\n",
    "sample_csv.to_csv(f'submision_baseline_{\"-\".join(X_columns)}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2] *",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
